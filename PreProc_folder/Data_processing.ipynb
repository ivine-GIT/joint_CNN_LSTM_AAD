{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import glob, os\n",
    "import scipy.io as sio\n",
    "from scipy.io import wavfile\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, signal\n",
    "from numpy.random import seed\n",
    "from scipy.signal import butter, lfilter, freqz, hilbert\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import librosa\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W:\\hno\\data\\gruppen\\Audiologie\\at900\\Studien\\Ivine\\My_papers\\DNN_Paper\\Github_to_Upload\\PreProc_folder\n"
     ]
    }
   ],
   "source": [
    "my_path = os.getcwd()\n",
    "print(my_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_if = 16000\n",
    "fs_eeg_final = 64\n",
    "\n",
    "win_len_sec = 3  # in sec\n",
    "hop_len_sec = 1  # 66.66 % overlap\n",
    "win_len = fs_if*win_len_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def List_files(directory,extension):\n",
    "    os.chdir(directory)\n",
    "    files=[]\n",
    "    for file in glob.glob(\"*.{}\".format(extension)):\n",
    "        files.append(file)\n",
    "\n",
    "    os.chdir(my_path)\n",
    "    print('pwd', os.getcwd())\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_Audio(datapath):\n",
    "    \n",
    "    name_seg = 'audio'  \n",
    "\n",
    "    audio = wavfile.read(datapath)\n",
    "    fs_orig = audio[0]\n",
    "    speech = audio[1]\n",
    "    \n",
    "    # added on 25.10\n",
    "    speech = speech[:, 0:2]/2**15\n",
    "    \n",
    "    Att1 = speech[:,0]\n",
    "    Att2 = speech[:,1]\n",
    "       \n",
    "    num_win = np.floor(np.shape(Att1)[0]/(hop_len_sec*fs_if))\n",
    "    num_win = int(num_win)\n",
    "    num_win -= 2\n",
    "    \n",
    "    print('Get Att1 resampled, shape:',np.shape(Att1),'Get Att2 resampled, shape:',np.shape(Att2), 'num_win', num_win)\n",
    "\n",
    "    Att_merge_dir = os.path.join(my_path,'Speech_data')\n",
    "    start_idx = 0\n",
    "    \n",
    "    for idx in range(0, num_win):\n",
    "        stop_idx = start_idx + win_len\n",
    "#         print(start_idx, stop_idx)\n",
    "\n",
    "        data_Att1 = Att1[start_idx : stop_idx]\n",
    "        data_Att2 = Att2[start_idx : stop_idx]\n",
    "        \n",
    "        features_att1 = np.abs(librosa.stft(y=data_Att1, n_fft=512, win_length=int(fs_if*32/1000), hop_length= int(fs_if*20/1000), window='hann'))**2\n",
    "        features_att2 = np.abs(librosa.stft(y=data_Att2, n_fft=512, win_length=int(fs_if*32/1000), hop_length= int(fs_if*20/1000), window='hann'))**2\n",
    "\n",
    "        if 0:\n",
    "            plt.plot(data_Att1)\n",
    "            plt.show()\n",
    "            plt.imshow(20*np.log10(features_att1), cmap='jet', interpolation='nearest', aspect='auto')\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "            \n",
    "            plt.plot(data_Att2)\n",
    "            plt.show()\n",
    "            plt.imshow(20*np.log10(features_att2), cmap='jet', interpolation='nearest', aspect='auto')\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "        \n",
    "        features_att1 = np.expand_dims(features_att1, axis=2)\n",
    "        features_att2 = np.expand_dims(features_att2, axis=2)\n",
    "        \n",
    "        features_merged = np.concatenate((features_att1/np.max(abs(features_att1)), features_att2/np.max(abs(features_att2))), axis=2)       \n",
    "        features_merged = np.transpose(features_merged, (1,0,2))         \n",
    "        \n",
    "        np.save(os.path.join(Att_merge_dir, name_seg + str(idx)), features_merged)\n",
    "        start_idx += int((hop_len_sec*fs_if))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pwd W:\\hno\\data\\gruppen\\Audiologie\\at900\\Studien\\Ivine\\My_papers\\DNN_Paper\\Github_to_Upload\\PreProc_folder\n",
      "['stim_1min.wav']\n",
      "Get Att1 resampled, shape: (960000,) Get Att2 resampled, shape: (960000,) num_win 58\n"
     ]
    }
   ],
   "source": [
    "audio_path = my_path + '\\\\'\n",
    "Name_raw_Audio = List_files(audio_path,'wav')\n",
    "print(Name_raw_Audio)\n",
    "\n",
    "for idx in np.arange(0, np.shape(Name_raw_Audio)[0]):\n",
    "    store_Audio(audio_path + Name_raw_Audio[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storing_EEG_HI(eeg_path, sub_id, csv_mode):\n",
    "    \n",
    "    matstruct_squeezed= sio.loadmat(eeg_path + sub_id)    \n",
    "    seg_num = 1\n",
    "    num_win = 58\n",
    "            \n",
    "    EEG_dir = os.path.join(my_path,'EEG')\n",
    "    hop_length = hop_len_sec*fs_eeg_final\n",
    "    \n",
    "#      -----   csv_mode   -----   #    \n",
    "#     'r': open for reading (default)\n",
    "#     'w': open for writing, truncating the file first\n",
    "#     'x': open for exclusive creation, failing if the file already exists\n",
    "#     'a': open for writing, appending to the end of the file if it exists\n",
    "#     'b': binary mode\n",
    "#     't': text mode (default)\n",
    "#     '+': open for updating (reading and writing)    \n",
    "                \n",
    "            \n",
    "    ## Making a EEG Dataset for useful 10 best channels\n",
    "    valid_idx = [3, 4, 6, 7, 9, 10, 11, 12, 13, 16]\n",
    "    \n",
    "    with open(my_path  + '\\\\Preproc_data.csv', csv_mode) as f:\n",
    "        writer = csv.writer(f, delimiter=\",\", lineterminator='\\n')\n",
    "\n",
    "        for seg_id in range(seg_num):\n",
    "            train_win_ids = np.arange(num_win)\n",
    "            \n",
    "            data_struct = matstruct_squeezed['seg'] # Loading EEG data for particular segment\n",
    "            attention = data_struct['attention'][0][0][0] # Extracting the 'attention' data\n",
    "            print(attention)\n",
    "            \n",
    "            if attention=='male1':\n",
    "                label=0\n",
    "            else:\n",
    "                label=1\n",
    "                            \n",
    "            ## Extracting EEG data from the particular segment\n",
    "            myarray = np.asarray(data_struct['eeg_env']) # convert EEG data to a array\n",
    "            array = myarray[0][0]\n",
    "                        \n",
    "            ## Making a EEG Dataset for useful 10 best channels\n",
    "            eeg_data_chans = array[:, valid_idx]\n",
    "            print(np.shape(eeg_data_chans))\n",
    "            \n",
    "            tmp_num_win = int(np.shape(eeg_data_chans)[0]/(hop_len_sec*fs_eeg_final)) \n",
    "#             print('num_win', tmp_num_win)\n",
    "            \n",
    "            for idx in train_win_ids:\n",
    "                start_idx = int(idx*hop_len_sec*fs_eeg_final)        \n",
    "                stop_idx = start_idx + int(win_len_sec*fs_eeg_final) \n",
    "                                           \n",
    "                sub_name = sub_id.split('_')[0]\n",
    "                f_name = sub_name + '_' + 'audio' + str(idx)\n",
    "#                 print(f_name, start_idx, stop_idx)\n",
    "\n",
    "                dataset = eeg_data_chans[start_idx:stop_idx, :]\n",
    "                np.save(os.path.join(EEG_dir,f_name), dataset)\n",
    "                writer.writerow((f_name, label)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pwd W:\\hno\\data\\gruppen\\Audiologie\\at900\\Studien\\Ivine\\My_papers\\DNN_Paper\\Github_to_Upload\\PreProc_folder\n",
      "['eeg_1min.mat']\n",
      "male2\n",
      "(3840, 10)\n"
     ]
    }
   ],
   "source": [
    "EEG_path = my_path + '\\\\'\n",
    "Name_EEG_files = List_files(EEG_path, 'mat')\n",
    "print(Name_EEG_files)\n",
    "\n",
    "for idx in np.arange(0, np.shape(Name_EEG_files)[0]):\n",
    "    storing_EEG_HI(EEG_path, Name_EEG_files[idx], 'w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv('Preproc_data.csv')\n",
    "\n",
    "p = 0.75 \n",
    "df_train = pd.read_csv('Preproc_data.csv', skiprows=lambda i: i>0 and np.random.random() > p)\n",
    "df_train.to_csv('train.csv', index=False)\n",
    "\n",
    "df_temp = pd.concat([df_orig, df_train]).drop_duplicates(keep=False)\n",
    "num_samples = int(df_temp.shape[0]/2)\n",
    "\n",
    "df_val = df_temp.head(num_samples)\n",
    "df_val.to_csv('validation.csv', index=False, header=None)\n",
    "\n",
    "df_test = df_temp.tail(num_samples)\n",
    "df_test.to_csv('test.csv', index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
